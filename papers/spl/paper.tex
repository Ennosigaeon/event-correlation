\documentclass[journal, 10pt]{IEEEtran}
%\documentclass[journal, 11pt, draft, onecolumn]{IEEEtran}


% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
	\graphicspath{{./figures/}}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex


% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm} % correct bold symbols, like \bm
\usepackage{mathrsfs}
%\usepackage[standard]{ntheorem}
\usepackage{theorem}
\usepackage{dsfont}
\usepackage{nicefrac}
\usepackage{mathtools}
\mathtoolsset{showonlyrefs}
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath



% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}



% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}


% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi



% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}



%\usepackage{stfloats}



%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi


% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}


\usepackage{color}
\def\Del#1{{\color{red}\sout{#1}}}
\def\OldNew#1#2{{\Del{#1}}{ \color{green}#2}}

\usepackage{multirow}
\usepackage[normalem]{ulem}
\usepackage{tikz}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\input{math}
\input{abbrev}
\input{TikZ}


\begin{document}
%
% paper title
\title{Temporal Lag Identification in Event Sequences by means of Linear Programming}
\title{Linear Programming based Temporal Lag Identification in Event Sequences}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Marco~F.~Huber,~\IEEEmembership{Member,~IEEE,}
        Marc-Andr\`e Z\"oller, %
        and~Marcus Baum,~\IEEEmembership{Member,~IEEE}% <-this % stops a space
\thanks{M. F.~Huber is with USU Software AG and Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany.
e-mail: \ttfamily{\scriptsize marco.huber@ieee.org}}% <-this % stops a space
\thanks{M.~Z\"oller and M.~Baum are with the Institute of Computer Science, University of G\"ottingen, Germany. e-mail: \ttfamily{\scriptsize marcus.baum@cs.uni-goettingen.de} }% <-this % stops a space
\thanks{Manuscript received MONTH xx, 2017; revised MONTH xx, 2017.}}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{IEEE Signal Processing Letters,~Vol.~xx, No.~xx, Month~2017}%
{FirstAuthor \MakeLowercase{\textit{et al.}}: Temporal Lag Identification in Event Sequences}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.


% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Many technical systems like manufacturing plants or software applications generate large event sequences. Knowing the temporal relationship between events is important for gaining insights into the status and behavior of the system. This paper proposes a novel approach for identifying the temporal lag between different event types. This identification task is formulated as a binary integer optimization problem that can be solved efficiently and close to optimality by means of a linear programming approximation. The performance of the proposed approach is demonstrated on artificial and real-world event sequences.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Event sequences, temporal lag, optimization, linear programming.
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
\label{sec:introduction}
Log files are a common way for collecting status information of technical systems and thus, are a valuable source for analyzing faults or anomalous system behavior. The data contained in these files can be  interpreted as a sequence of events. In the most basic case an event contains some kind of label and a timestamp. In addition, events are often enriched with supplementary information like messages, component description, or input data. 

Events normally do not appear independently. Instead, they influence and trigger each other. With a certain complexity of the monitored system, a manual inspection of all events becomes impractical. Thus, from the 1980s on efforts for automating event processing started. Early approaches were expert systems, where a domain expert explicitly defined rules and dependencies between event types, cf. \cite{Houck1995, Kettschau2002}. 
Creating rules, however, is very time consuming, difficult, and error prone and transferring rules to a new domain is often not possible.

Generic approaches utilize time windows for finding correlated event pairs based on their relative frequency \cite{Jakobson1993, Mannila1997, Bouandas2007}. A major difficulty here is the selection of an appropriate window size. A too small window may lead to missed correlated event pairs, while a too large window size may cause false positive correlations. 

In \cite{Zeng2015}, temporal dependencies among events are exploited for identifying correlated event pairs. Therefore, the temporal lag between two event types is estimated by means of expectation-maximization (EM). This approach is considered as current state-of-the-art and serves as a performance reference for event correlation throughout this work.

In this paper, a novel approach for estimating the temporal lag between event pairs is proposed. This estimation is formulated as an optimization problem. To solve it also for large event sequences in a computationally efficient manner, two approximations leading to a relaxed linear program formulation of the original problem are introduced. It is proven that the induced approximation error is limited and thus, a near-optimal solution can be found in polynomial time. 

The next section gives a problem description. \Sec{sec:lp} describes the linear programming based temporal lag identification.
Numerical results on synthetic and real-world data are provided in \Sec{sec:results}. 
The paper concludes with \Sec{sec:conclusion}.

\section{Problem Statement}
\label{sec:problem}
%
It is assumed that the system under consideration generates a sequence of events $\SE = \{e_1, e_2, \ldots, e_k\}$ with pairs $e_i = (E_i, t_i)$, where $E_i \in \Omega$ is the actual event stemming from an event space $\Omega$ and $t_i$ is the timestamp of the event with $0<t_i < t_{i+1}$ and $i=1,2,\ldots,k$. %The events in $\SE$ are sorted in ascending order with respect to the timestamps.

The focus of this paper is on identifying the temporal relationship between two types of events $A$ and $B$ from $\Omega$. Let $\SE_A = \{a_1, a_2, \ldots, a_m\}$ be a sub-sequence of $\SE$ comprising all events of type $A$. For simplicity and as we are merely interested on the temporal dependency, from now on $a_i$ synonymously refers to the timestamp of the $i$-th event in $\SE_A$. Analogously, $\SE_B = \{b_1, b_2, \ldots, b_n\}$ represents the timestamps of all events of type $B$ in $\SE$.

To model the relation between events $a_i$ and $b_j$ we introduce a latent \emph{assignment variable} $z_{ij} \in \{0,1\}$.
This variable is equal to one if $a_i$ triggers $b_j$, otherwise $z_{ij} = 0$. As we are interested in event types where there are no arbitrary relations, we make the following realistic assumptions.

\begin{Assumption}%[One to many]
\label{as:one-to-many}
An event of type $B$ can only be triggered by one event of type $A$, i.e., $\textstyle\sum_{i=1}^m z_{ij}=1$  for all $j=1,\ldots,n$.
\end{Assumption}

\begin{Assumption}
\label{as:b}
An event of type $A$ can trigger at most one event of type $B$, i.e., $\textstyle\sum_{j=1}^n z_{ij}\le 1$  for all $i=1,\ldots,m$.
\end{Assumption}

In the triggering case, i.e., where $z_{ij} = 1$, $a_i$ is called the \emph{trigger event} and $b_j$ is the \emph{response event}.
The response event follows the trigger event with some \emph{temporal lag} $\delta$ that is considered a random variable, as this lag may vary due to (unkown) interferences caused by the system. Thus, for specific event pairs $a_i$ and $b_j$, the actual temporal lag
%
\begin{equation}
	\delta_{ij} = b_j - a_i
	\label{eq:temporal-lag}
\end{equation}
%
is considered a realization or sample of $\delta$. 

\begin{Assumption}
\label{as:positive-lags}
A response event cannot occur before the trigger event, i.e., $\delta_{ij}\ge 0$ for all $i=1,\ldots,m$ and $j=1,\ldots,n$.
\end{Assumption}

According to \cite{Zeng2015}, the mean and the variance of $\delta$ can be calculated according to
%
\begin{align}
	\label{eq:mean}
	\mu &= \E[\delta] = \tfrac{1}{n} \sum_{i=1}^m\sum_{j=1}^n z_{ij}\cdot \delta_{ij}~,
	\\
	\label{eq:variance}
	\sigma^2 &= \Var[\delta] = \tfrac{1}{n}\sum_{i=1}^m\sum_{j=1}^n z_{ij} \cdot (\delta_{ij} - \mu)^2~,
\end{align}
%
respectively. 


\section{Temporal Lag Identification}
\label{sec:lp}
%
Estimating the temporal lag~$\delta$ between events of type $A$ and $B$ is considered as finding the correct assignment of trigger events to response events such that the variance of $\delta$ is minimized. This corresponds to the optimization problem
%
\begin{align}
	\label{eq:optimization-problem}
	\min_{\vz} \ \Var[\delta] \ & \\
	\text{s.t.} \hspace{4mm} \H \cdot \vz &= \vec 1_p~,\\
		 \D \cdot \vz &\le \vec 1_p~, \\
	 \mat \Delta \cdot \vz &\ge \vec 0_p~, \\
		\vz &\in \{0,1\}^p~,
	%\text{s.t.} \hspace{4mm} \mat Z\T\cdot \vec 1 &= \vec 1~,\\
		 %\mat Z\cdot \vec 1 &\le \vec 1~, \\
	 %\diag(\vec \delta) \cdot \vz &\ge \vec 0~, \\
		%\mat Z &\in \{0,1\}^{m\times n}~,
\end{align}
%
where the first three constraints reflect the Assumptions~\ref{as:one-to-many}--\ref{as:positive-lags} with $\vec 0_p$ and $\vec 1_p$ being vectors of zeros and ones, respectively, of dimension $p=m\cdot n$, 
$\H \DEF \I_n \otimes \vec 1_m\T$ with identity matrix $\I_n$ of dimension $n\times n$, Kronecker product $\otimes$, and matrix transpose $(.)\T$, 
$\mat D \DEF \vec 1_n\T \otimes \I_m$, 
$\mat \Delta \DEF \diag(\vec \delta)$ being a diagonal matrix with elements from  
%$\odot$ being the Hadamard product, 
%$\vec \delta\T = \[\vec \delta_1\T\ \vec \delta_2\T\ \ldots\ \vec \delta_m\T\]$ with $\vec \delta_i = \[\delta_{i1}\ \delta_{i2} \ \ldots\ \delta_{im}\]$ being the vectors of all temporal lags, 
$\vec \delta \DEF [\delta_{11}\ \delta_{21} \ldots \delta_{mn}]\T$ being the vector of all temporal lags, and
$\vz \DEF [z_{11}\ z_{21} \ldots z_{mn}]\T$ being the vector of all assignment variables.%, and %, where $z_{ij}$ is in row $i$ and column $j$ of $\mat Z$. $\mathrm{vec}(\A)$ being a matrix-vectorization operator converting a matrix $\A$ into a vector by stacking the columns of $\A$.

Given the previously introduced vectors $\vz$ and $\vec \delta$, the variance in \eqref{eq:variance} and \eqref{eq:optimization-problem} can be rewritten in vector notation to
%
\begin{equation}
 \Var[\delta] = \tfrac{1}{n} \cdot \(\(\vec \delta\odot\vec\delta\)\T\cdot \vz - \tfrac{1}{n}\cdot\vz\T\cdot\vec\delta\cdot\vec\delta\T\cdot\vz \)~.
\label{eq:variance-vector}
\end{equation}
%
%
%\begin{equation}
 %\Var\[\delta\] = \tfrac{1}{n-1} \cdot \( \(\mat \Delta\odot\mat\Delta\)\otimes \mat Z - \tfrac{1}{n}\cdot \trace\(\mat Z\mat\Delta \cdot \(\mat \Delta\mat Z\)\T\)\)%\(\mat Z\cdot \mat \Delta\) \otimes \(\mat Z\cdot\mat \Delta\)\T\)
%\label{eq:variance-vector-matrix}
%\end{equation}
%
%$\otimes$ being the Frobenius inner product, i.e., a Hadamard product followed by the summation of all elements of the resulting matrix.
Due to the binary nature of $\vz$ and the quadratic form in~\eqref{eq:variance-vector}, the problem in \eqref{eq:optimization-problem} corresponds to a so-called \emph{binary quadratic program} and thus, is NP-hard \cite{Katayama2001}. A computationally feasible solution merely exists for very short event sequences. To also allow the identification of temporal lags in large event sequences, an approximation is proposed that relies on the following two steps: (i) neglecting the quadratic term $\vz\T\cdot\vec\delta\cdot\vec\delta\T\cdot\vz$ in \eqref{eq:variance-vector} and (ii) relaxation of the binary constraint $\vz \in \{0,1\}^p$.

\subsection{Linear Approximation}
\label{sec:lp_linear}
%
As the quadratic term in \eqref{eq:variance-vector} can also be expressed as 
%
\begin{equation}
	\vz\T\cdot\vec\delta\cdot\vec\delta\T\cdot\vz = \(\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}\cdot z_{ij}\)^2
\label{eq:quadratic-term}
\end{equation}
%
it becomes apparent that it is always non-negative. Thus, neglecting it results into a upper-bound approximation to \eqref{eq:variance-vector}, which is linear and equivalent to the expected value $\E\hspace{-.5mm}\big[\delta^2 \big]$. Furthermore, it can be shown that neglecting \eqref{eq:quadratic-term} introduces only a small approximation error.

\begin{Theorem}
For $m,n \rightarrow \infty$ the quadratic term \eqref{eq:quadratic-term} approaches zero.
\end{Theorem}
%
\begin{Proof}
As the variance \eqref{eq:variance-vector} by definition is always non-negative, it holds that
%
\begin{equation}
	\(\vec \delta\odot\vec\delta\)\T\cdot \vz\ \ge\ \tfrac{1}{n}\cdot\vz\T\cdot\vec\delta\cdot\vec\delta\T\cdot\vz~,
\label{eq:linear-ge-quadratic}
\end{equation}
%
i.e., the linear term in \eqref{eq:variance-vector} dominates the quadratic one. Furthermore, by considering the ratio
%
\begin{equation}
	\alpha \DEF \frac{\(\vec \delta\odot\vec\delta\)\T\cdot \vz}{\vz\T\cdot\vec\delta\cdot\vec\delta\T\cdot\vz} 
	= \frac{\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}^2\cdot z_{ij}}{\big(\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}\cdot z_{ij}\big)^2}~,
\label{eq:ratio}
\end{equation}
%
which is bounded from above by one, it is possible to evaluate the influence of the quadratic term.
%
%\begin{align}
	%\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}^2\cdot z_{ij} 
	%&= \sum_{i=1}^m \sum_{j=1}^n \delta_{ij}^2\cdot z_{ij}^2\\
	%&= \sum_{i=1}^m \sum_{j=1}^n \(\delta_{ij}\cdot z_{ij}\)^2\\
	%&\le \(\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}\cdot z_{ij}\)^2\\
	%&\le \sum_{i=1}^m \delta_{ij}^2\cdot \sum_{j=1}^n z_{ij}^2
%\end{align}
%
By applying the Cauchy-Schwarz inequality, this ratio becomes
%
\begin{align}
	\alpha 
	&\ge \frac{\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}^2\cdot z_{ij}}{\sum_{i=1}^m \sum_{j=1}^n 1^2 \cdot \sum_{i=1}^m \sum_{j=1}^n \big(\delta_{ij}\cdot z_{ij}\big)^2} \\
	&= \frac{\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}^2\cdot z_{ij}}{m\cdot n \cdot \sum_{i=1}^m \sum_{j=1}^n \big(\delta_{ij}\cdot z_{ij}\big)^2} \\
	&= \frac{\sum_{i=1}^m \sum_{j=1}^n \delta_{ij}^2\cdot z_{ij}}{m\cdot n \cdot \sum_{i=1}^m \sum_{j=1}^n \delta_{ij}^2\cdot z_{ij}} \\
	&= \frac{1}{m\cdot n}~.
\label{eq:lower-bound}
\end{align}
%
The equality in the third line follows from the fact that $z_{ij}$ is binary. In case of $z_{ij}$ being continuous with $z_{ij} \in [0,1]$, this equality turns into a greater-equal relation. Thus, this proof also holds for a relaxed formulation of the optimization problem, as it is considered in \Sec{sec:lp_relax}.
\end{Proof}

Thus, for an increasing number of events, the quadratic term vanishes as the ratio $\alpha$ approaches zero. 

		
\subsection{Continuous Relaxation}
\label{sec:lp_relax}
%
Even by removing the quadratic term, the resulting binary linear program (BLP) is still NP-hard. % due to constraining $z_{ij}$ to be binary. 
In order to reduce the complexity of the optimization problem, it is a common approach to \emph{relax} the problem. That is, instead of requiring the binary constraint $z_{ij}\in\{0,1\}$, the assignment variable is allowed to be continuous on the unity interval, i.e., $z_{ij} \in [0,1]$. The relaxation of BLP yields a linear program (LP)
%
\begin{align}
	\label{eq:relaxed-optimization-problem}
	\min_{\vz} \ \E\hspace{-.5mm}\big[\delta^2 \big] \ & \\
	\text{s.t.} \hspace{4mm} \H \cdot \vz &= \vec 1_p~,\\
		 \D \cdot \vz &\le \vec 1_p~, \\
	 \mat \Delta \cdot \vz &\ge \vec 0_p~, \\
		\vz &\in [0,1]^p~,
	%\text{s.t.} \hspace{4mm} \mat Z\T\cdot \vec 1 &= \vec 1~,\\
		 %\mat Z\cdot \vec 1 &\le \vec 1~, \\
	 %\diag(\vec \delta) \cdot \vz &\ge \vec 0~, \\
		%\mat Z &\in \{0,1\}^{m\times n}~,
\end{align}
%
which is solvable in polynomial time by many algorithms, for example the famous \emph{Simplex} algorithm \cite{NelderMead1965}. 

Obviously, the relaxation modifies and approximates the original BLP problem. This approximation usually introduces an additional error called the \emph{integrality gap} \cite{Arora2002}. Fortunately, under special circumstances, the LP is theoretically even able to find binary solutions without an approximation error being induced by the relaxation. Thus, the original BLP problem can be solved exactly even for large event sequences. 

\begin{Theorem}
The relaxed LP in \eqref{eq:relaxed-optimization-problem} is equivalent to the BLP problem. Thus, there exists a polynomial-time solution for the BLP.
\end{Theorem}

This theorem can be proven by showing that the LP always finds a binary solution if and only if the constraint matrices $\H$, $\D$, and $\mat \Delta$ in \eqref{eq:relaxed-optimization-problem} are \emph{totally unimodular} \cite{Sierksma2001}.

%It has to be shown that the relaxation does not increase the error too much. 
%
%\begin{Corollary}
%The cost of the LP solution is a lower bound to the cost of the BLP solution.
%\end{Corollary}
%
%This corollary follows from that fact that the solution space of the BLP is completely contained in the LP solution space. 
%Under special circumstances, LP is theoretically even able to find binary solutions and thus, to solve the original BLP problem exactly. More specifically, LP always finds a binary solution if and only if the constraint matrices $\H$, $\D$, and $\mat \Delta$ in \eqref{eq:relaxed-optimization-problem} are \emph{totally unimodular} \cite{Sierksma2001}.

\begin{Definition}
A matrix $\A$ is called totally unimodular if every square sub-matrix of $\A$ is unimodular. A square matrix $\A$ is called unimodular if $|\A| = \pm 1$, where $|.|$ is the determinant.
\end{Definition}

%Hence, instead of estimating the approximation error, it is proven in the following that the constraints are totally unimodular and consequently, no approximation error has been induced by the relaxation. For this purpose, the following corollary is helpful.

\begin{Corollary}
\label{cor:totally-unimodular}
Any matrix $\A$ containing only $-1$, $0$, and $1$ elements is totally unimodular if each column of $\A$ contains at most two non-zero elements. Furthermore, all rows of $\A$ can be split into two sets such that two non-zero elements with the same sign from one column belong to different sets and two non-zero elements with different sign from one column belong to the same set.
\end{Corollary}

See Theorem~7.3 in \cite{Sierksma2001} for a proof of Corollary~\ref{cor:totally-unimodular}. Based on this corollary, $\H$ and $\D$ are totally unimodular as they contain only $0$ and $1$ with only one $1$ per column. However, $\mat \Delta$ has to be rewritten to
$\mat \Delta = \diag\big(\vec{\tilde \delta}\big)$ with $\vec{\tilde \delta} \DEF \big[\sign(\delta_{11})\ \sign(\delta_{21})\ \ldots\ \sign(\delta_{mn})\big]\T$ and $\sign(.)$ being the signum function, in order to fulfill the first condition in Corollary~\ref{cor:totally-unimodular}. This reformulation is not changing the optimal solution to \eqref{eq:relaxed-optimization-problem}. As $\mat \Delta$ now comprises only $-1$ and $1$ with only one non-zero element per column, it is also totally unimodular.


\subsection{Potential Extensions}
\label{sec:lp_extensions}
%
Besides the constraints considered for the identification problem in \eqref{eq:optimization-problem}, it is also possible to impose additional, more application-specific constraints. For instance:

\begin{enumerate}
	\item Assumption~\ref{as:one-to-many} can be relaxed by allowing that a response event can be triggered by more than one event, e.g., $\textstyle\sum_i z_{ij} \le N \in \NewN$.
	\item A trigger event can create more than one response event by relaxing Assumption~\ref{as:b}, e.g., $\textstyle\sum_j z_{ij} \le M\in \NewN$.
	\item Instead of merely avoiding negative temporal lags as in Assumption~\ref{as:positive-lags}, it is also possible to define bounds, e.g., $\tau \le \delta_{ij} \le T$ where $\tau, T \in \NewR^+$ and $\tau < T$.
	\item If many events trigger a single response event, it is possible to define a bound on the time difference between the trigger events. For example, if two events $a_i$ and $a_j$ are necessary to trigger an event $b_k$, then the time difference between both trigger events has to be below $D \in \NewR^+$, which corresponds to $\delta_{ik}-\delta_{jk} \le D$.
\end{enumerate}

All these constraints can be expressed with constraint matrices being totally unimodular and thus, solving the estimation problem close to optimality in a computationally cheap manner still holds.


\subsection{Comparison}
\label{sec:lp_comparison}
%
BLPs for solving assignment problems as in \eqref{eq:optimization-problem} have been studied extensively in the literature for many applications like sensor selection \cite{Moon2017} or resource allocation \cite{Sultan2011}, but not for the temporal lag identification problem as considered in this paper. However, some general purpose BLP solution algorithms could also be applied here. For instance, for the special case of $\SE_A$ and $\SE_B$ being of the same length, i.e., $m=n$, the optimal solution to \eqref{eq:optimization-problem} can also be found via sorting, which is computationally the most efficient approach. Unfortunately, besides this special case and for extended versions of the considered problem as discussed in the previous section, sorting no longer works. The same holds for the well-known Hungarian algorithm \cite{Kuhn1955}.

Closest to the proposed LP is the so-called \emph{lagEM} algorithm introduced in \cite{Zeng2015}. Here, the temporal lag between two event sequences is estimated by means of an expectation-maximization (EM) approach. For this purpose, it is assumed that the distribution of the temporal lag is Gaussian. As any EM algorithm, also lagEM can only find sub-optimal solutions and thus, requires a good initialization in order to find a meaningful result. In contrast to lagEM, LP always finds the optimal solution and makes no assumptions about the temporal lag distribution. Thus, by means of \eqref{eq:mean} and \eqref{eq:variance}, it is also possible to calculate a near-optimal Gaussian distribution approximating the true distribution, but without the limitations of lagEM.


\section{Results}
\label{sec:results}
%
The proposed LP temporal lag identification approach is evaluated in the following on synthetically generated event sequences as well as on a real-world event log of a \emph{Symantec Endpoint Protection} virus scanner. LP is compared against the ground truth and the results of lagEM by means of the runtime as well as
the standardized deviation between the true and estimated mean and variance
%
\begin{equation}
	\Delta_\mu = \tfrac{|\tilde \mu - \mu|}{\sigma}~\text{ and }~\Delta_\sigma = \tfrac{|\tilde \sigma - \sigma|}{\sigma}~,
	\label{eq:std-deviation}
\end{equation}
%
respectively. Here, the tilde indicates the estimated value. 
Furthermore, based on the assignments found, the temporal lag distribution is calculated via a kernel density estimator (KDE), where each event pair is interpreted as a sample. For the KDE, a Gaussian kernel is employed and its bandwidth is selected by Scott's rule-of-thumb~\cite{Scott1992}. For quantifying the similarity between the true distribution and the KDE estimate, the normalized squared integral deviation (SID)~\cite{Fusion08_Huber_PGMR}
%
\begin{equation}
	\text{SID}\big(\tilde f(\delta), f(\delta)\big) = \frac{\int \big(\tilde f(\delta) - f(\delta)\big)^2 \dd \delta}{\int \tilde f(\delta)^2\dd \delta + \int f(\delta)^2 \dd \delta} \in [0,1]
\label{eq:}
\end{equation}
%
is calculated, with $\tilde f$ being the KDE estimate and $f$ being the true distribution. A value of zero corresponds to identical distributions, while a one indicates non-overlapping distributions.

For all experiments, LP stops if it converges or the number of iterations exceeds 200. In the latter case, the examined event pair is considered as not correlated.

\begin{table}%
\centering
\caption{}
\label{}
\begin{tabular}{c|cccc|cccc}
\multirow{2}{5mm}{Sce-nario} & \multicolumn{4}{c|}{\textbf{LP}} & \multicolumn{4}{c}{\textbf{lagEM}}
\\
 & $\Delta_\mu$ & $\Delta_\sigma$ & SID & time & $\Delta_\mu$ & $\Delta_\sigma$ & SID & time
\\ \hline
 1 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00
\\
 2 & 0.00 & 0.00 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0
\\ \hline
 3 & 0.00 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0
\\
 4 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0
\\
 5 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0
\end{tabular}
\end{table}


\subsection{Synthetic Event Sequences}
\label{sec:results_synthetic}
%
Two synthetic sequences are generated and analyzed as described in the following.

\subsubsection{Scenario 1}
At first, a sequence used by Zeng at al. is considered (see Table I in \cite{Zeng2015}), which comprises $200$ events in total. The occurrence of event $A$ follows an exponential distribution with $\beta = 27.5$. Event $B$ follows after event $A$ with a normally distributed temporal lag $\mathcal{N}(77.01, 6.664)$. All events are lost with a probability of 10\%.

Figure \ref{fig:scen1} shows the estimated distributions. Although nearly all event pairs overlap, LP is able to estimate the true distribution with a low SID of $xxx$. Even with several retries, lagEM was not able to estimate the correct distribution, which is also reflected in the calculated distance of $0.3839$. Zeng et al. reported the same behavior but were able to solve it by using longer sequences \cite{Zeng2015}.


\subsubsection{Scenario 2}
This scenario introduces two additional event types. Furthermore, the temporal lag is not modeled by normal distributions. A sequence contains $1000$ events in total. Event $A$ appears according to the uniform distribution $\mathcal{U}(30, 50)$. Event $B$ follows after event $A$ with an exponentially distributed temporal lag with $\beta = 10$ and an offset of $25$. Independently of $A$ and $B$ an additional event pair exists. Event $C$ occurs based on an exponential distribution with $\beta = 25$ and an offset of $10$. Event $D$ follows after event $C$ with a uniformly distributed temporal lag $\mathcal{U}(15, 25)$. Again, all event types are lost with a probability of 10\%.

According to \Fig{}, both algorithms provide a good estimate of the temporal lag distribution between type $A$ and $B$ events.
Even though, LP misses the long tail, the SID is quite low with $xxx$. The lagEM algorithm estimates the mean precisely, but the probability of small or even negative time lags is overestimated. This is caused by the inherent assumption that the temporal lag is normally distributed. Nevertheless, the estimate is merely slightly worse than LP.

A similar behavior can be observed for events $C$ and $D$ (see \Fig{}). lagEM estimates the correct mean, but the variance is too large as a uniform distribution can hardly be approximated by a normal distribution. %This yields a higher distance of $0.1976$. 
In contrast, LP (SID~=~$xxx$) provides a better estimate. The jittery probability density can be explained by the limited number of samples.

\subsection{Symantec Events}
\label{sec:results_symantec}
%
The Symantec event log covers the time span from March 5, 2015 to March 10, 2016 and contains in total $3742$ events of $19$ different types. 
In the following some exemplary detected event pairs are discussed, where \Tab{tab:symantecEvents} contains a short description of the involved event types. 

\begin{table}[!ht]
	\caption{Excerpt of all event types in the Symantec log file with a short description and the number of occurrences.}
	\label{tab:symantecEvents}

	\centering
	\begin{tabular}{c p{0.3\textwidth} c}
		Event ID & \multicolumn{1}{c}{Description} & Count \\
		\hline
		\textit{2}	& Symantec finishes a hard drive scan & 8 \\
		\textit{3}	& Symantec starts a hard drive scan & 10 \\
		\textit{7}	& A virus definition with new threat descriptions has been found & 308 \\
		\textit{65}	& Symantec antivirus scan suspended & 36 \\
		\textit{66}	& Symantec antivirus scan continued & 38 \\
	\end{tabular}

\end{table}

\section{Conclusion and Future Work}
\label{sec:conclusion}
%


\appendices
% use section* for acknowledgment
\section*{Acknowledgment}
This work was partially supported by the BMWi project SAKE (Grant No. 01MD15006A).


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section
\bibliographystyle{IEEEtran}
\bibliography{literature}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:
%
%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}
%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


